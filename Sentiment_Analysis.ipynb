{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/david/github/galvanize/post_grad/sentiment_analysis_imdbdata/train/pos'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + 'data/train/pos'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/david/github/galvanize/post_grad/sentiment_analysis_imdb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_train = []\n",
    "for root, dirs, files in os.walk('data/train/pos'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                pos_list_train.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think that most of the folks who have posted comments on this movie don't understand how to watch a movie and/or have little sense of elegance. First, to assess a movie you need to understand the extent to which everything in the film works together. Modern sensibilities demand great drama. No, I don't mean great setting of characters and plots, but they seem to demand emotional trajectories that are greatly tragic or greatly comedic. This is a subtle movie. Its beauty lies in its subtlety (not to be confused with simplicity). Neither the story nor the characters are simple in this movie. It is a beautifully filmed movie that makes the most of combining sensuousness, politics, human weakness, venality...you name it. The world it's set in would be alien and not understood today...a world where if you have it you have to flaunt it NOW and LOUDLY, even if you only think you have it.<br /><br />Many people today don't understand that Victorian society wasn't really Victorian as people understand that term today.<br /><br />This movie helps set the record straight.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_list_train = []\n",
    "for root, dirs, files in os.walk('data/train/neg'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                neg_list_train.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are some movies you just know they are going to be bad from frame one. Even if you were totally oblivious of Ed Wood\\'s work, one look at that commentator from \"Plan 9 from outer space\" and you just KNOW you are not gonna see the next cinematic masterpiece. Just like that, when I saw the first shot of Uwe Bolls masterpiece \"House of Dead\", with that guy sitting at the front of the house starting his introduction while trying desperately to sound like he just arrived from Sin City, I knew I\\'m in for a helluva ride.<br /><br />So, the movie starts like this - first the lead character says that everybody else is going to die. You know, to keep you wandering. Then he starts introducing the rest of the characters with lines like \"Karma..thinks she\\'s Foxy Brown\" or \"Alicia..my ex.. we broke up recently.. I had to study and she had to fence\". No, I\\'m not kidding.<br /><br />Anyway, this bunch of 20-somethings who couldn\\'t act their way out of a wet paper-bag are going to the \"Rave of the century\", rave in question being a few tents, a port-a-potty and a shoddy stage located on small island in the middle of the Pacific. Our gang missed the ferry, but thankfully will find a way to get there, the way being a fisher-boat ran by Kirk (Cpt Kirk? Get it? Man, whoever wrote this script is a genius) and his sidekick who is a bastard child of Simpsons\\' Cpt McAllister and that hook killer who knows what you did last summer.<br /><br />To make the long story short, the gang gets to the island, finds nobody there except some bloody T-shirts and then decide to run the hell away from there. No wait, they do not, they actually get all happy and like cos there\\'s free booze.<br /><br />With that scene the movie hits rock bottom and then against all odds proceeds to go further downhill. Some guys in rubber suits start running around, there is some screaming and shooting, our gang goes to some house to meet some other gang, they go out of the house, meet Cpt Kirk and some police woman (who between them have about 500 pounds of weapons) and then decide to go back to the house. Somewhere along the line they transform into a S.W.A.T. team, enter the Matrix, the rubber-suit guys start multiplying like bacteria and I start to cry because I actually paid to see this. To add insult to the injury, every few minutes there are shots from the video game this crap is based on and there is a cute game-over cut-scene for a few characters when they die.<br /><br />I seriously hate this movie. It doesn\\'t even fit in that famed \"So bad it\\'s good\" category. It\\'s just plain bad. The script is bad, the zombies are awful, there is no tension, lines are bad, actors are bad.. the list just goes on.<br /><br />You will probably want to see this movie just because of its reputation of being awful. Don\\'t. There are bad movies that deserve to be watched. This is not one of them.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_list_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having is bets'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "s = \"having \\|is bet's\"\n",
    "s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['having positively tomorrows', 'beings absolutely positively largest']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [\"HAving pos,itively tomorrow\\'s\"\n",
    "             , \"BEing'/s absolutely\\! POSitively largest\"]\n",
    "\n",
    "test_cleaned = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in test_list]\n",
    "test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_train = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in pos_list_train]\n",
    "neg_list_train = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in neg_list_train]\n",
    "all_list_train = pos_list_train + neg_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_test = []\n",
    "for root, dirs, files in os.walk('data/test/pos'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                pos_list_test.append(text)\n",
    "\n",
    "                \n",
    "neg_list_test = []\n",
    "for root, dirs, files in os.walk('data/test/neg'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                neg_list_test.append(text)\n",
    "                \n",
    "pos_list_test = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in pos_list_test]\n",
    "neg_list_test = [x.translate(str.maketrans('', '', string.punctuation)).lower() for x in neg_list_test]\n",
    "all_list_test = pos_list_test + neg_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary = True)\n",
    "cv.fit(all_list_train)\n",
    "X = cv.transform(all_list_train)\n",
    "X_test = cv.transform(all_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C = 0.01 is 0.8741818181818182\n",
      "Accuracy for C = 0.05 is 0.8829090909090909\n",
      "Accuracy for C = 0.1 is 0.8838787878787879\n",
      "Accuracy for C = 0.15 is 0.8824242424242424\n",
      "Accuracy for C = 0.2 is 0.8819393939393939\n",
      "Accuracy for C = 0.25 is 0.8812121212121212\n",
      "Accuracy for C = 0.35 is 0.8798787878787879\n",
      "Accuracy for C = 0.5 is 0.8779393939393939\n",
      "Accuracy for C = 0.75 is 0.8778181818181818\n",
      "Accuracy for C = 1 is 0.8766060606060606\n"
     ]
    }
   ],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X\n",
    "                                                  , target\n",
    "                                                  , train_size = 0.67\n",
    "                                                  , random_state = 42\n",
    "                                                 )\n",
    "\n",
    "for regularization in [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.35, 0.5, 0.75, 1]:\n",
    "    lr = LogisticRegression(C=regularization)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(f'Accuracy for C = {regularization} is {accuracy_score(y_val, lr.predict(X_val))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C = 0.1 is best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.88308\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(C=0.1)\n",
    "logistic_model.fit(X, target)\n",
    "print(f'Best model accuracy: {accuracy_score(target, logistic_model.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000000000001',\n",
       " '000001',\n",
       " '00000110',\n",
       " '0001',\n",
       " '00015',\n",
       " '001',\n",
       " '0010',\n",
       " '002',\n",
       " '00383042',\n",
       " '006',\n",
       " '007',\n",
       " '0079',\n",
       " '0080',\n",
       " '0083',\n",
       " '00s',\n",
       " '01',\n",
       " '010',\n",
       " '01000',\n",
       " '010br',\n",
       " '010makes',\n",
       " '0110',\n",
       " '012310',\n",
       " '0130',\n",
       " '013007',\n",
       " '02',\n",
       " '029',\n",
       " '02br',\n",
       " '03',\n",
       " '0310',\n",
       " '03oct2009',\n",
       " '04',\n",
       " '041',\n",
       " '048',\n",
       " '05',\n",
       " '050',\n",
       " '0510',\n",
       " '053105',\n",
       " '06',\n",
       " '06th',\n",
       " '07',\n",
       " '079',\n",
       " '07kiloton',\n",
       " '08',\n",
       " '081006',\n",
       " '087',\n",
       " '089',\n",
       " '08th',\n",
       " '09',\n",
       " '09082009',\n",
       " '091505',\n",
       " '09br',\n",
       " '0br',\n",
       " '0f',\n",
       " '0ne',\n",
       " '0r',\n",
       " '0s',\n",
       " '0stars',\n",
       " '0when',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '10000000',\n",
       " '1000000000000',\n",
       " '1000000000000010000000000000',\n",
       " '10002000',\n",
       " '1000lb',\n",
       " '1000s',\n",
       " '1001',\n",
       " '100200',\n",
       " '100am',\n",
       " '100b',\n",
       " '100br',\n",
       " '100hell',\n",
       " '100kin',\n",
       " '100m',\n",
       " '100min',\n",
       " '100minute',\n",
       " '100mph',\n",
       " '100percent',\n",
       " '100plus',\n",
       " '100s',\n",
       " '100square',\n",
       " '100th',\n",
       " '100thgrade',\n",
       " '100x',\n",
       " '100yards',\n",
       " '100year',\n",
       " '100yearold',\n",
       " '100years',\n",
       " '101',\n",
       " '1010',\n",
       " '1010br',\n",
       " '1010seek',\n",
       " '1011',\n",
       " '1012',\n",
       " '1013',\n",
       " '1014',\n",
       " '101499',\n",
       " '1015',\n",
       " '101503',\n",
       " '101575',\n",
       " '101706',\n",
       " '101br',\n",
       " '101minute',\n",
       " '101st',\n",
       " '101year',\n",
       " '101yearold',\n",
       " '102',\n",
       " '1020',\n",
       " '1020000',\n",
       " '102030',\n",
       " '1025',\n",
       " '102862',\n",
       " '102955',\n",
       " '102nd',\n",
       " '103',\n",
       " '1030',\n",
       " '1030pm',\n",
       " '103104',\n",
       " '1035',\n",
       " '104',\n",
       " '1040',\n",
       " '1040a',\n",
       " '1040s',\n",
       " '105',\n",
       " '1050',\n",
       " '105lbs',\n",
       " '106',\n",
       " '107',\n",
       " '1072000',\n",
       " '1072007',\n",
       " '1075',\n",
       " '108',\n",
       " '109',\n",
       " '1095',\n",
       " '109minute',\n",
       " '10am',\n",
       " '10br',\n",
       " '10but',\n",
       " '10check',\n",
       " '10day',\n",
       " '10dirarne',\n",
       " '10dirbrad',\n",
       " '10direwald',\n",
       " '10dirjim',\n",
       " '10dirjohn',\n",
       " '10dirjon',\n",
       " '10dirmichael',\n",
       " '10dirmick',\n",
       " '10dirsteve',\n",
       " '10dirsydney',\n",
       " '10dirtobe',\n",
       " '10foot',\n",
       " '10highly',\n",
       " '10hour',\n",
       " '10i',\n",
       " '10if',\n",
       " '10its',\n",
       " '10just',\n",
       " '10line',\n",
       " '10lines',\n",
       " '10master',\n",
       " '10min',\n",
       " '10minute',\n",
       " '10of',\n",
       " '10of10',\n",
       " '10page',\n",
       " '10pm',\n",
       " '10s',\n",
       " '10scale',\n",
       " '10second',\n",
       " '10speed',\n",
       " '10star',\n",
       " '10th',\n",
       " '10the',\n",
       " '10they',\n",
       " '10this',\n",
       " '10times',\n",
       " '10well',\n",
       " '10x',\n",
       " '10x10',\n",
       " '10xs',\n",
       " '10year',\n",
       " '10yearlater',\n",
       " '10yearold',\n",
       " '10yearolds',\n",
       " '10yr',\n",
       " '10yrold',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '11001001',\n",
       " '1100ad',\n",
       " '1100th',\n",
       " '11072004',\n",
       " '110br',\n",
       " '110jd',\n",
       " '110minute',\n",
       " '110th',\n",
       " '111',\n",
       " '1110',\n",
       " '111128',\n",
       " '1112009',\n",
       " '111232',\n",
       " '1113',\n",
       " '111but',\n",
       " '111minute',\n",
       " '112',\n",
       " '112001sandler',\n",
       " '112101',\n",
       " '11240',\n",
       " '112413',\n",
       " '112443',\n",
       " '1131516',\n",
       " '1138',\n",
       " '1139',\n",
       " '114',\n",
       " '1146',\n",
       " '115',\n",
       " '115minruntime',\n",
       " '116',\n",
       " '11673',\n",
       " '116th',\n",
       " '117',\n",
       " '1172002',\n",
       " '119',\n",
       " '11br',\n",
       " '11m',\n",
       " '11minute',\n",
       " '11th',\n",
       " '11year',\n",
       " '11yearold',\n",
       " '11yearsold',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12000',\n",
       " '12000000',\n",
       " '12007',\n",
       " '1200f',\n",
       " '1200pm',\n",
       " '1201',\n",
       " '1201pm',\n",
       " '1202',\n",
       " '120page',\n",
       " '12100',\n",
       " '121031',\n",
       " '12106',\n",
       " '1213',\n",
       " '1214',\n",
       " '1215',\n",
       " '121566',\n",
       " '121am',\n",
       " '12242009',\n",
       " '12262008',\n",
       " '12272006',\n",
       " '123',\n",
       " '123000000',\n",
       " '12312006',\n",
       " '12345',\n",
       " '1235',\n",
       " '12383499143743701',\n",
       " '1245am',\n",
       " '125',\n",
       " '125000',\n",
       " '125150',\n",
       " '125m',\n",
       " '1262009',\n",
       " '12638',\n",
       " '127',\n",
       " '1272002',\n",
       " '128',\n",
       " '1282001',\n",
       " '12a',\n",
       " '12br',\n",
       " '12episode',\n",
       " '12foot',\n",
       " '12h',\n",
       " '12hour',\n",
       " '12hr',\n",
       " '12m',\n",
       " '12minute',\n",
       " '12mm',\n",
       " '12pack',\n",
       " '12s',\n",
       " '12th',\n",
       " '12th14th',\n",
       " '12thrateat',\n",
       " '12year',\n",
       " '12yearold',\n",
       " '12yearolds',\n",
       " '12years',\n",
       " '12yrold',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '13000',\n",
       " '1300s',\n",
       " '130am',\n",
       " '131',\n",
       " '1314',\n",
       " '1318',\n",
       " '132',\n",
       " '133',\n",
       " '1331',\n",
       " '1331br',\n",
       " '1335',\n",
       " '1335is',\n",
       " '1336th',\n",
       " '134',\n",
       " '134minute',\n",
       " '135',\n",
       " '13516',\n",
       " '135m',\n",
       " '136',\n",
       " '137',\n",
       " '1371br',\n",
       " '138',\n",
       " '138minute',\n",
       " '139',\n",
       " '13and',\n",
       " '13br',\n",
       " '13but',\n",
       " '13episode',\n",
       " '13inch',\n",
       " '13k',\n",
       " '13rd',\n",
       " '13s',\n",
       " '13th',\n",
       " '13thbr',\n",
       " '13thclone',\n",
       " '13thi',\n",
       " '13thversions',\n",
       " '13year',\n",
       " '13yearold',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '1408',\n",
       " '1408br',\n",
       " '140am',\n",
       " '140hp',\n",
       " '140minute',\n",
       " '1410',\n",
       " '1415',\n",
       " '1415yearold',\n",
       " '1416',\n",
       " '1416s',\n",
       " '1417',\n",
       " '142minute',\n",
       " '1430',\n",
       " '145',\n",
       " '1451',\n",
       " '145150',\n",
       " '1454',\n",
       " '146',\n",
       " '147',\n",
       " '1473',\n",
       " '147br',\n",
       " '149',\n",
       " '1492',\n",
       " '1498',\n",
       " '1499',\n",
       " '14a',\n",
       " '14br',\n",
       " '14goingon9',\n",
       " '14ieme',\n",
       " '14inch',\n",
       " '14minute',\n",
       " '14th',\n",
       " '14x',\n",
       " '14year',\n",
       " '14yearold',\n",
       " '14yearoldgirl',\n",
       " '14yearolds',\n",
       " '14yo',\n",
       " '14yrold',\n",
       " '14ème',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '15000',\n",
       " '150000',\n",
       " '1500000',\n",
       " '15000000',\n",
       " '1500sbr',\n",
       " '1500sera',\n",
       " '150k',\n",
       " '150m',\n",
       " '150minute',\n",
       " '151',\n",
       " '1510',\n",
       " '1516',\n",
       " '1516yearsold',\n",
       " '1517',\n",
       " '1518',\n",
       " '152',\n",
       " '1520',\n",
       " '153',\n",
       " '154',\n",
       " '1547',\n",
       " '155',\n",
       " '156',\n",
       " '1561',\n",
       " '157',\n",
       " '158',\n",
       " '1594',\n",
       " '1599',\n",
       " '15as',\n",
       " '15br',\n",
       " '15bus',\n",
       " '15hrs',\n",
       " '15mins',\n",
       " '15minute',\n",
       " '15minutes',\n",
       " '15odd',\n",
       " '15second',\n",
       " '15th',\n",
       " '15thcentury',\n",
       " '15to18',\n",
       " '15year',\n",
       " '15yearold',\n",
       " '15yearolds',\n",
       " '15years',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '16000',\n",
       " '1600s',\n",
       " '160lbs',\n",
       " '160page',\n",
       " '161',\n",
       " '1610',\n",
       " '1617',\n",
       " '1627',\n",
       " '163',\n",
       " '163000',\n",
       " '163minute',\n",
       " '164',\n",
       " '165',\n",
       " '165m',\n",
       " '166',\n",
       " '1660s',\n",
       " '1661',\n",
       " '168',\n",
       " '169',\n",
       " '1692',\n",
       " '1697',\n",
       " '169minute',\n",
       " '16bit',\n",
       " '16ieme',\n",
       " '16k',\n",
       " '16minute',\n",
       " '16mm',\n",
       " '16mmstyle',\n",
       " '16rated',\n",
       " '16s',\n",
       " '16th',\n",
       " '16thcentury',\n",
       " '16x9',\n",
       " '16year',\n",
       " '16yearld',\n",
       " '16yearold',\n",
       " '16yrold',\n",
       " '16ème',\n",
       " '16éme',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '17000',\n",
       " '1700s',\n",
       " '1700sbr',\n",
       " '171',\n",
       " '1718',\n",
       " '172003',\n",
       " '175',\n",
       " '177',\n",
       " '1775',\n",
       " '177583',\n",
       " '1780s',\n",
       " '1781br',\n",
       " '1790s',\n",
       " '179495',\n",
       " '1798',\n",
       " '17inch',\n",
       " '17th',\n",
       " '17thcentury',\n",
       " '17year',\n",
       " '17yearold',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '18000',\n",
       " '18000000',\n",
       " '1800makeover',\n",
       " '1800mph',\n",
       " '1800s',\n",
       " '1800sbr',\n",
       " '1800smans',\n",
       " '18011844',\n",
       " '1805',\n",
       " '1809',\n",
       " '180d',\n",
       " '1812',\n",
       " '1813',\n",
       " '1814',\n",
       " '1816',\n",
       " '1820',\n",
       " '1820s',\n",
       " '1824',\n",
       " '1825',\n",
       " '183',\n",
       " '1830',\n",
       " '1830s',\n",
       " '1832',\n",
       " '1835',\n",
       " '1836',\n",
       " '1837',\n",
       " '1837this',\n",
       " '1838',\n",
       " '1839',\n",
       " '183minute',\n",
       " '1840',\n",
       " '18401911',\n",
       " '1840s',\n",
       " '1840sbr',\n",
       " '1846',\n",
       " '1847',\n",
       " '185',\n",
       " '1850',\n",
       " '1850ies',\n",
       " '1850s',\n",
       " '1851',\n",
       " '1851br',\n",
       " '1853',\n",
       " '1854',\n",
       " '1855',\n",
       " '1859',\n",
       " '18591860',\n",
       " '1860',\n",
       " '18601909',\n",
       " '18602',\n",
       " '1860s',\n",
       " '1861',\n",
       " '1862',\n",
       " '1863',\n",
       " '1864',\n",
       " '1865',\n",
       " '1870',\n",
       " '1870s',\n",
       " '1871',\n",
       " '1873',\n",
       " '18741965',\n",
       " '1875br',\n",
       " '1876',\n",
       " '1880',\n",
       " '1880s',\n",
       " '1881',\n",
       " '1886',\n",
       " '1887',\n",
       " '1888',\n",
       " '1889',\n",
       " '188minute',\n",
       " '188o',\n",
       " '1890',\n",
       " '1890s',\n",
       " '1890sbr',\n",
       " '1892',\n",
       " '1893',\n",
       " '1894',\n",
       " '1895',\n",
       " '1895br',\n",
       " '1896',\n",
       " '18961899',\n",
       " '18961982',\n",
       " '1896jeff',\n",
       " '1897',\n",
       " '1898',\n",
       " '1898br',\n",
       " '1899',\n",
       " '18a',\n",
       " '18rated',\n",
       " '18th',\n",
       " '18thcentury',\n",
       " '18year',\n",
       " '18yearold',\n",
       " '18yearsold',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '19000000',\n",
       " '1900s',\n",
       " '1900sbr',\n",
       " '1901',\n",
       " '1902',\n",
       " '1902ii',\n",
       " '1903',\n",
       " '1904',\n",
       " '1905',\n",
       " '1905br',\n",
       " '1906',\n",
       " '19061952',\n",
       " '1907',\n",
       " '1908',\n",
       " '1909',\n",
       " '1909s',\n",
       " '1910',\n",
       " '1910s',\n",
       " '1911',\n",
       " '191112',\n",
       " '1912',\n",
       " '1913',\n",
       " '1914',\n",
       " '1915',\n",
       " '1915br',\n",
       " '1916',\n",
       " '1917',\n",
       " '19172000br',\n",
       " '1918',\n",
       " '191820',\n",
       " '1918it',\n",
       " '1919',\n",
       " '192',\n",
       " '1920',\n",
       " '19201939',\n",
       " '19201998',\n",
       " '1920helping',\n",
       " '1920ies',\n",
       " '1920s',\n",
       " '1920sbr',\n",
       " '1920sspring',\n",
       " '1921',\n",
       " '1922',\n",
       " '1922br',\n",
       " '1922most',\n",
       " '1923',\n",
       " '1924',\n",
       " '19241940',\n",
       " '1924kriemhild',\n",
       " '1925',\n",
       " '1926',\n",
       " '1927',\n",
       " '19271928',\n",
       " '1927s',\n",
       " '1928',\n",
       " '1928s',\n",
       " '1929',\n",
       " '192930',\n",
       " '1929his',\n",
       " '1930',\n",
       " '19301935',\n",
       " '193031',\n",
       " '1930and',\n",
       " '1930br',\n",
       " '1930comedy',\n",
       " '1930europe',\n",
       " '1930iesbr',\n",
       " '1930s',\n",
       " '1930sbecause',\n",
       " '1930sbr',\n",
       " '1930sera',\n",
       " '1930speter',\n",
       " '1930sset',\n",
       " '1930sstyle',\n",
       " '1930sthis',\n",
       " '1931',\n",
       " '19311942',\n",
       " '193139',\n",
       " '1931br',\n",
       " '1932',\n",
       " '19323',\n",
       " '193234',\n",
       " '1932s',\n",
       " '1933',\n",
       " '19331939',\n",
       " '19332005',\n",
       " '19334',\n",
       " '1933s',\n",
       " '1933when',\n",
       " '1934',\n",
       " '19341938',\n",
       " '19345',\n",
       " '1934br',\n",
       " '1934s',\n",
       " '1935',\n",
       " '1935s',\n",
       " '1935very',\n",
       " '1936',\n",
       " '19361945',\n",
       " '19361946',\n",
       " '193637',\n",
       " '1936br',\n",
       " '1936in',\n",
       " '1937',\n",
       " '1937br',\n",
       " '1937s',\n",
       " '1938',\n",
       " '19381981',\n",
       " '1938s',\n",
       " '1939',\n",
       " '19391942',\n",
       " '193940',\n",
       " '193945',\n",
       " '1939br',\n",
       " '1939i',\n",
       " '1939in',\n",
       " '1939may',\n",
       " '1939out',\n",
       " '1939s',\n",
       " '193os',\n",
       " '194',\n",
       " '1940',\n",
       " '19401941',\n",
       " '19401943',\n",
       " '19401944',\n",
       " '194041',\n",
       " '1940br',\n",
       " '1940by',\n",
       " '1940just',\n",
       " '1940may',\n",
       " '1940s',\n",
       " '1940s1950sranging',\n",
       " '1940s50s',\n",
       " '1940s60s',\n",
       " '1940sbut',\n",
       " '1940the',\n",
       " '1941',\n",
       " '19411943',\n",
       " '19411945',\n",
       " '19411991',\n",
       " '1941br',\n",
       " '1941s',\n",
       " '1942',\n",
       " '1942br',\n",
       " '1942era',\n",
       " '1942february',\n",
       " '1942july',\n",
       " '1943',\n",
       " '1943br',\n",
       " '1944',\n",
       " '194445',\n",
       " '1944s',\n",
       " '1944the',\n",
       " '1945',\n",
       " '19452000',\n",
       " '1945br',\n",
       " '1945film',\n",
       " '1946',\n",
       " '19461949',\n",
       " '194666',\n",
       " '1946br',\n",
       " '1947',\n",
       " '19471948',\n",
       " '194748',\n",
       " '1947br',\n",
       " '1947i',\n",
       " '1947s',\n",
       " '1948',\n",
       " '1948br',\n",
       " '1948s',\n",
       " '1949',\n",
       " '194950',\n",
       " '1949br',\n",
       " '1949er',\n",
       " '1949s',\n",
       " '195',\n",
       " '1950',\n",
       " '195051',\n",
       " '1950br',\n",
       " '1950of',\n",
       " '1950s',\n",
       " '1950s1960s',\n",
       " '1950s60s',\n",
       " '1950sbefore',\n",
       " '1950sbr',\n",
       " '1950sesque',\n",
       " '1950sfaithful',\n",
       " '1950sness',\n",
       " '1950sprinceton',\n",
       " '1950sstyle',\n",
       " '1950sstyled',\n",
       " '1950stewart',\n",
       " '1950version',\n",
       " '1951',\n",
       " '19512001',\n",
       " '1951br',\n",
       " '1952',\n",
       " '19522002',\n",
       " '195255',\n",
       " '1952br',\n",
       " '1953',\n",
       " '195354',\n",
       " '19537',\n",
       " '1953br',\n",
       " '1953i',\n",
       " '1953s',\n",
       " '1954',\n",
       " '1954all',\n",
       " '1955',\n",
       " '195519561957',\n",
       " '19551965',\n",
       " '195556',\n",
       " '195559',\n",
       " '195564',\n",
       " '1955br',\n",
       " '1955s',\n",
       " '1956',\n",
       " '1956and',\n",
       " '1956s',\n",
       " '1956title',\n",
       " '1957',\n",
       " '19571963',\n",
       " '1957br',\n",
       " '1957s',\n",
       " '1958',\n",
       " '1958and',\n",
       " '1958stands',\n",
       " '1958titanic',\n",
       " '1959',\n",
       " '19591965',\n",
       " '19591973',\n",
       " '195960br',\n",
       " '1959br',\n",
       " '1959s',\n",
       " '1960',\n",
       " '19601980',\n",
       " '1960hardly',\n",
       " '1960s',\n",
       " '1960s1970s',\n",
       " '1960s70s',\n",
       " '1960sbr',\n",
       " '1960searly',\n",
       " '1960sstyle',\n",
       " '1960sthats',\n",
       " '1960sunderwear',\n",
       " '1960there',\n",
       " '1961',\n",
       " '1961s',\n",
       " '1962',\n",
       " '1962br',\n",
       " '1962s',\n",
       " '1963',\n",
       " '19631989',\n",
       " '1963the',\n",
       " '1964',\n",
       " '19641968',\n",
       " '196468',\n",
       " '1965',\n",
       " '1965br',\n",
       " '1965s',\n",
       " '1966',\n",
       " '1966s',\n",
       " '1966sons',\n",
       " '1967',\n",
       " '19671973',\n",
       " '1967br',\n",
       " '1967has',\n",
       " '1967s',\n",
       " '1968',\n",
       " '196819',\n",
       " '19681988',\n",
       " '196877',\n",
       " '1968br',\n",
       " '1968type',\n",
       " '1969',\n",
       " '19691972',\n",
       " '196970',\n",
       " '196974br',\n",
       " '1969br',\n",
       " '1969s',\n",
       " '1969starring',\n",
       " '1969the',\n",
       " '197',\n",
       " '1970',\n",
       " '1970ies',\n",
       " '1970s',\n",
       " '1970s80s',\n",
       " '1970sand',\n",
       " '1970sbr',\n",
       " '1970searly',\n",
       " '1970si',\n",
       " '1970sincluding',\n",
       " '1970sitalian',\n",
       " '1970sstyle',\n",
       " '1970years',\n",
       " '1971',\n",
       " '1971br',\n",
       " '1972',\n",
       " '197273',\n",
       " '1972br',\n",
       " '1972i',\n",
       " '1972s',\n",
       " '1973',\n",
       " '197376br',\n",
       " '1973br',\n",
       " '1973s',\n",
       " '1973watching',\n",
       " '1974',\n",
       " '19741979',\n",
       " '19741980',\n",
       " '19745',\n",
       " '1974a',\n",
       " '1974br',\n",
       " '1974groundbreaker',\n",
       " '1974s',\n",
       " '1974safari',\n",
       " '1975',\n",
       " '197583',\n",
       " '1975br',\n",
       " '1975s',\n",
       " '1976',\n",
       " '19761984',\n",
       " '197677',\n",
       " '1976br',\n",
       " '1976s',\n",
       " '1977',\n",
       " '19772006',\n",
       " '1977br',\n",
       " '1977s',\n",
       " '1978',\n",
       " '19781979',\n",
       " '197879',\n",
       " '197892',\n",
       " '1978on',\n",
       " '1978s',\n",
       " '1979',\n",
       " '19796',\n",
       " '197982',\n",
       " '1979is',\n",
       " '1979s',\n",
       " '197o',\n",
       " '198',\n",
       " '1980',\n",
       " '1980br',\n",
       " '1980i',\n",
       " '1980ies',\n",
       " '1980if',\n",
       " '1980s',\n",
       " '1980sat',\n",
       " '1980sboom',\n",
       " '1980sbr',\n",
       " '1980si',\n",
       " '1981',\n",
       " '198182',\n",
       " '1981br',\n",
       " '1981i',\n",
       " '1981s',\n",
       " '1982',\n",
       " '19821951',\n",
       " '198283',\n",
       " '1982br',\n",
       " '1982et',\n",
       " '1982in',\n",
       " '1982s',\n",
       " '1983',\n",
       " '198385br',\n",
       " '1983back',\n",
       " '1983br',\n",
       " '1983i',\n",
       " '1983s',\n",
       " '1984',\n",
       " '19841985',\n",
       " '1984br',\n",
       " '1984critters',\n",
       " '1984i',\n",
       " '1984ish',\n",
       " '1984while',\n",
       " '1985',\n",
       " '1985br',\n",
       " '1985most',\n",
       " '1986',\n",
       " '1986onward',\n",
       " '1986s',\n",
       " '1986wannabe',\n",
       " '1987',\n",
       " '1987all',\n",
       " '1987br',\n",
       " '1987not',\n",
       " '1987s',\n",
       " '1988',\n",
       " '198889',\n",
       " '1988br',\n",
       " '1988mostly',\n",
       " '1988of',\n",
       " '1988s',\n",
       " '1989',\n",
       " '1989br',\n",
       " '1989s',\n",
       " '199',\n",
       " '1990',\n",
       " '1990a',\n",
       " '1990br',\n",
       " '1990really',\n",
       " '1990s',\n",
       " '1990sbr',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.33215955e-05, -1.10521807e-05, -6.27687569e-03, ...,\n",
       "       -1.04390243e-04,  4.92097490e-04, -1.90989756e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_coef_set = {word: coef for word, coef in zip(cv.get_feature_names()\n",
    "                                                     , logistic_model.coef_[0]\n",
    "                                                    )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('710', 1.2939769814705733)\n",
      "('excellent', 1.0449014803876946)\n",
      "('perfect', 0.8551987054227257)\n",
      "('810', 0.7868112964124089)\n",
      "('refreshing', 0.7551410271518383)\n",
      "('superb', 0.7362386845116279)\n",
      "('great', 0.7168697283583562)\n",
      "('amazing', 0.7138616284349564)\n",
      "('wonderfully', 0.6993792776896967)\n",
      "('incredible', 0.6895514330627024)\n",
      "('enjoyable', 0.6859858760625969)\n",
      "('rare', 0.6710719146504849)\n",
      "('loved', 0.6693180918720015)\n",
      "('1010', 0.6673692698542227)\n",
      "('wonderful', 0.6662443654188439)\n",
      "('favorite', 0.6647374607375903)\n",
      "('highly', 0.6592649388160386)\n",
      "('subtle', 0.6588928823936371)\n",
      "('today', 0.635718453933966)\n",
      "('funniest', 0.6297576612842508)\n",
      "('perfectly', 0.6243534518346844)\n",
      "('gem', 0.6055523470243495)\n",
      "('enjoyed', 0.602668588479384)\n",
      "('surprisingly', 0.602653813483567)\n",
      "('fantastic', 0.5855827094545735)\n",
      "('appreciated', 0.5687204629311867)\n",
      "('noir', 0.5572705241114464)\n",
      "('best', 0.5546499778199583)\n",
      "('910', 0.5516157933003557)\n",
      "('simple', 0.550946574731809)\n"
     ]
    }
   ],
   "source": [
    "for best_pos in sorted(feature_coef_set.items(), key=lambda x: x[1], reverse=True)[:30]:\n",
    "    print(best_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worst', -1.5463585240451676)\n",
      "('waste', -1.3881983548183023)\n",
      "('410', -1.1849986394701963)\n",
      "('awful', -1.1574020055622694)\n",
      "('poorly', -1.093773270049877)\n",
      "('disappointment', -1.0545492409639323)\n",
      "('boring', -0.9241988622070391)\n",
      "('dull', -0.8703489800066017)\n",
      "('disappointing', -0.842300506881872)\n",
      "('lacks', -0.817478506834414)\n",
      "('terrible', -0.8087310681090566)\n",
      "('310', -0.8032572047354193)\n",
      "('fails', -0.8022068222288903)\n",
      "('avoid', -0.7986310753699828)\n",
      "('mess', -0.7869988129960698)\n",
      "('worse', -0.7763050687755154)\n",
      "('poor', -0.7638440531928534)\n",
      "('bad', -0.7607692209161956)\n",
      "('horrible', -0.7567420058573258)\n",
      "('laughable', -0.7439892006999067)\n",
      "('annoying', -0.7366963819168318)\n",
      "('forgettable', -0.7042155640055943)\n",
      "('unfunny', -0.6909051714293039)\n",
      "('save', -0.6850473252668037)\n",
      "('lame', -0.6744773440201364)\n",
      "('badly', -0.6703078047849595)\n",
      "('unfortunately', -0.6693027771746188)\n",
      "('210', -0.6658815210525404)\n",
      "('weak', -0.6335144684842836)\n",
      "('lousy', -0.6269404242067491)\n"
     ]
    }
   ],
   "source": [
    "for best_neg in sorted(feature_coef_set.items(), key=lambda x: x[1])[:30]:\n",
    "    print(best_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    cleaned = []\n",
    "    for x in corpus:\n",
    "        cleaned.append(' '.join([y for y in x.split() if y not in stop_words]))\n",
    "    return cleaned\n",
    "\n",
    "all_list_train = remove_stop_words(all_list_train)\n",
    "all_list_test = remove_stop_words(all_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes call perfect movie one boring second fantastic cast mostly little known actresses actors great array characters well defined understandable motives could sympathize perfect lighting crisp black white photography fitting soundtrack intelligent harmonious set design story engaging works one prime quality pictures pride hollywood rest mark everyone endeavor reachbr br barbara stanwyck simply stunning nothing actress couldnt always went easy melodramatic side hysterical outbursts lady always thought better actress screen goddesses like bette davis joan crawford movie confirmed opinion always tough nails time conveying true sentiments fair add also got many good parts long career one far least interestingbr br title fits movie well desires human desires think everyone understand actually one seems scheming movie characters act impulse everybody wants happy without hurting anybody else sad fact often leads complications makes dramatic content go herebr br liked movie say youth maturing necessity compromise movie associate one alfred hitchcocks shadow doubt creates similar atmosphere idealized time caricatured small town america story certain similarity fritz langs considerably harsher movie clash night made one year earlier stanywck stars similar part also recommend'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dont torture duckling absolutely stunning giallo diversion lucio fulci unlike subgenre heavyweights like mario bava dario argento fulci takes decidedly gritty grounded socially perceptive approach giallo narrative film nothing glamorous child murders borderline pedophilia gutsy subplot 1972 going fulci wisely shoots staid lugubrious eye avoiding flash melodrama directorial histrionics proceedings punctuated gory instantly mindsearing set pieces bolstered even fulcis jarring sense realism\\x97 deeply disturbing witch killing scene particular baldfaced brutality feels like snuff film composer riz ortolani bookends carnagefilled scenes ferocious reverberating string blastsbr br film capped simultaneously lyrical violent conclusion wherein theology morality fanaticism superstition collide deeply effective ending capacity leave viewer befuddled disarmed torporbr br fulci couldnt picked better location film dont torture duckling photographed around ancient city matera italy matera continues modernize day highlighted shift agricultural economy industrial one grappling unescosponsored reputation receptacle mysterious paleolithic ghosts anxieties reallife materani reflected characters film wearing christianity sleeves fretfully confront exotic fringe tradition namely witchcraft strays outside normbr br interestingly enough matera also used standin jerusalem mel gibsons passion christ anything adds even potency fulcis message catholic guilt grisly slayings resonant combination'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have posit tomorrow\n",
      "time positive tomorrow\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "test_list = ['having positively tomorrows'\n",
    "             , 'being absolutely positively largest']\n",
    "\n",
    "def token_stem(sent):\n",
    "    sent = word_tokenize(sent)\n",
    "    lst = []\n",
    "    for x in sent:\n",
    "        lst.append(ps.stem(x))\n",
    "    return ' '.join(lst)\n",
    "\n",
    "def token_lem(sent):\n",
    "    sent = word_tokenize(sent)\n",
    "    lst = []\n",
    "    for x in sent:\n",
    "        lst.append(lm.lemmatize(x))\n",
    "    return ' '.join(lst)\n",
    "\n",
    "print(token_stem('having positives tomorrows'))\n",
    "print(token_lem('times positives tomorrows'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['having positively tomorrow', 'being absolutely positively largest']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [token_lem(x) for x in test_list]\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list_train_stem = [token_stem(x) for x in all_list_train]\n",
    "all_list_test_stem = [token_stem(x) for x in all_list_test]\n",
    "\n",
    "all_list_train_lem = [token_lem(x) for x in all_list_train]\n",
    "all_list_test_lem = [token_lem(x) for x in all_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye call perfect movi one bore second fantast cast mostli littl known actress actor great array charact well defin understand motiv could sympath perfect light crisp black white photographi fit soundtrack intellig harmoni set design stori engag work one prime qualiti pictur pride hollywood rest mark everyon endeavor reachbr br barbara stanwyck simpli stun noth actress couldnt alway went easi melodramat side hyster outburst ladi alway thought better actress screen goddess like bett davi joan crawford movi confirm opinion alway tough nail time convey true sentiment fair add also got mani good part long career one far least interestingbr br titl fit movi well desir human desir think everyon understand actual one seem scheme movi charact act impuls everybodi want happi without hurt anybodi els sad fact often lead complic make dramat content go herebr br like movi say youth matur necess compromis movi associ one alfr hitchcock shadow doubt creat similar atmospher ideal time caricatur small town america stori certain similar fritz lang consider harsher movi clash night made one year earlier stanywck star similar part also recommend\n",
      "\n",
      "dont tortur duckl absolut stun giallo divers lucio fulci unlik subgenr heavyweight like mario bava dario argento fulci take decidedli gritti ground social percept approach giallo narr film noth glamor child murder borderlin pedophilia gutsi subplot 1972 go fulci wise shoot staid lugubri eye avoid flash melodrama directori histrion proceed punctuat gori instantli mindsear set piec bolster even fulci jar sens realism deepli disturb witch kill scene particular baldfac brutal feel like snuff film compos riz ortolani bookend carnagefil scene feroci reverber string blastsbr br film cap simultan lyric violent conclus wherein theolog moral fanatic superstit collid deepli effect end capac leav viewer befuddl disarm torporbr br fulci couldnt pick better locat film dont tortur duckl photograph around ancient citi matera itali matera continu modern day highlight shift agricultur economi industri one grappl unescosponsor reput receptacl mysteri paleolith ghost anxieti reallif materani reflect charact film wear christian sleev fret confront exot fring tradit name witchcraft stray outsid normbr br interestingli enough matera also use standin jerusalem mel gibson passion christ anyth add even potenc fulci messag cathol guilt grisli slay reson combin\n",
      "\n",
      "yes call perfect movie one boring second fantastic cast mostly little known actress actor great array character well defined understandable motif could sympathize perfect lighting crisp black white photography fitting soundtrack intelligent harmonious set design story engaging work one prime quality picture pride hollywood rest mark everyone endeavor reachbr br barbara stanwyck simply stunning nothing actress couldnt always went easy melodramatic side hysterical outburst lady always thought better actress screen goddess like bette davis joan crawford movie confirmed opinion always tough nail time conveying true sentiment fair add also got many good part long career one far least interestingbr br title fit movie well desire human desire think everyone understand actually one seems scheming movie character act impulse everybody want happy without hurting anybody else sad fact often lead complication make dramatic content go herebr br liked movie say youth maturing necessity compromise movie associate one alfred hitchcock shadow doubt creates similar atmosphere idealized time caricatured small town america story certain similarity fritz langs considerably harsher movie clash night made one year earlier stanywck star similar part also recommend\n",
      "\n",
      "dont torture duckling absolutely stunning giallo diversion lucio fulci unlike subgenre heavyweight like mario bava dario argento fulci take decidedly gritty grounded socially perceptive approach giallo narrative film nothing glamorous child murder borderline pedophilia gutsy subplot 1972 going fulci wisely shoot staid lugubrious eye avoiding flash melodrama directorial histrionics proceeding punctuated gory instantly mindsearing set piece bolstered even fulcis jarring sense realism deeply disturbing witch killing scene particular baldfaced brutality feel like snuff film composer riz ortolani bookend carnagefilled scene ferocious reverberating string blastsbr br film capped simultaneously lyrical violent conclusion wherein theology morality fanaticism superstition collide deeply effective ending capacity leave viewer befuddled disarmed torporbr br fulci couldnt picked better location film dont torture duckling photographed around ancient city matera italy matera continues modernize day highlighted shift agricultural economy industrial one grappling unescosponsored reputation receptacle mysterious paleolithic ghost anxiety reallife materani reflected character film wearing christianity sleeve fretfully confront exotic fringe tradition namely witchcraft stray outside normbr br interestingly enough matera also used standin jerusalem mel gibson passion christ anything add even potency fulcis message catholic guilt grisly slaying resonant combination\n"
     ]
    }
   ],
   "source": [
    "print(all_list_train_stem[0])\n",
    "print('\\n' + all_list_test_stem[0])\n",
    "print('\\n' + all_list_train_lem[0])\n",
    "print('\\n' + all_list_test_lem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.89056,\n",
       " 0.892,\n",
       " 0.89312,\n",
       " 0.8928,\n",
       " 0.89296,\n",
       " 0.8928,\n",
       " 0.89312,\n",
       " 0.89264,\n",
       " 0.89264,\n",
       " 0.8928,\n",
       " 0.89312,\n",
       " 0.89328,\n",
       " 0.89328,\n",
       " 0.89312,\n",
       " 0.89312,\n",
       " 0.89312,\n",
       " 0.89296,\n",
       " 0.8928,\n",
       " 0.8928,\n",
       " 0.8928]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vect = CountVectorizer(binary=True\n",
    "                             , ngram_range=(1,2)\n",
    "                            )\n",
    "\n",
    "lst_train = all_list_train_stem # change stem/lem train list here\n",
    "lst_test = all_list_test_stem # change stem/lem test list here\n",
    "\n",
    "ngram_vect.fit(lst_train)\n",
    "X = ngram_vect.transform(lst_train)\n",
    "X_test = ngram_vect.transform(lst_test)\n",
    "\n",
    "target = [1 if x < 12500 else 0 for x in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X\n",
    "                                                  , target\n",
    "                                                  , train_size=0.75\n",
    "                                                  , random_state=42\n",
    "                                                 )\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "for c in [x/20 for x in range(1,21)]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_list.append((accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "lr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05, 0.89056),\n",
       " (0.1, 0.892),\n",
       " (0.15, 0.89312),\n",
       " (0.2, 0.8928),\n",
       " (0.25, 0.89296),\n",
       " (0.3, 0.8928),\n",
       " (0.35, 0.89312),\n",
       " (0.4, 0.89264),\n",
       " (0.45, 0.89264),\n",
       " (0.5, 0.8928),\n",
       " (0.55, 0.89312),\n",
       " (0.6, 0.89328),\n",
       " (0.65, 0.89328),\n",
       " (0.7, 0.89312),\n",
       " (0.75, 0.89312),\n",
       " (0.8, 0.89312),\n",
       " (0.85, 0.89296),\n",
       " (0.9, 0.8928),\n",
       " (0.95, 0.8928),\n",
       " (1.0, 0.8928)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x/20, y) for x, y in zip(range(1,21), lr_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05, 0.88896),\n",
       " (0.1, 0.88992),\n",
       " (0.15, 0.89136),\n",
       " (0.2, 0.89152),\n",
       " (0.25, 0.89104),\n",
       " (0.3, 0.89136),\n",
       " (0.35, 0.89152),\n",
       " (0.4, 0.89152),\n",
       " (0.45, 0.89184),\n",
       " (0.5, 0.89264),\n",
       " (0.55, 0.89248),\n",
       " (0.6, 0.89248),\n",
       " (0.65, 0.89248),\n",
       " (0.7, 0.89264),\n",
       " (0.75, 0.89296),\n",
       " (0.8, 0.89312),\n",
       " (0.85, 0.89312),\n",
       " (0.9, 0.89296),\n",
       " (0.95, 0.89312),\n",
       " (1.0, 0.8928)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vect = CountVectorizer(binary=True\n",
    "                             , ngram_range=(1,2)\n",
    "                            )\n",
    "\n",
    "lst_train_lem = all_list_train_lem # change stem/lem train list here\n",
    "lst_test_lem = all_list_test_lem # change stem/lem test list here\n",
    "\n",
    "ngram_vect.fit(lst_train_lem)\n",
    "X = ngram_vect.transform(lst_train_lem)\n",
    "X_test = ngram_vect.transform(lst_test_lem)\n",
    "\n",
    "target = [1 if x < 12500 else 0 for x in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X\n",
    "                                                  , target\n",
    "                                                  , train_size=0.75\n",
    "                                                  , random_state=42\n",
    "                                                 )\n",
    "\n",
    "lr_list_lem = []\n",
    "\n",
    "for c in [x/20 for x in range(1,21)]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_list_lem.append((accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "lr_list_lem = [(x/20, y) for x, y in zip(range(1,21), lr_list_lem)]\n",
    "lr_list_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.04,\n",
       " 0.05,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.1,\n",
       " 0.11,\n",
       " 0.12,\n",
       " 0.13,\n",
       " 0.14]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x/100 for x in range(1,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.87952),\n",
       " (0.02, 0.8864),\n",
       " (0.03, 0.88672),\n",
       " (0.04, 0.88928),\n",
       " (0.05, 0.88896),\n",
       " (0.06, 0.88976),\n",
       " (0.07, 0.8896),\n",
       " (0.08, 0.88992),\n",
       " (0.09, 0.88992),\n",
       " (0.1, 0.88992),\n",
       " (0.11, 0.89008),\n",
       " (0.12, 0.89024),\n",
       " (0.13, 0.89056),\n",
       " (0.14, 0.89104),\n",
       " (0.15, 0.89136)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_list_lem = []\n",
    "\n",
    "for c in [x/100 for x in range(1,16)]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_list_lem.append((accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "lr_list_lem = [(x/100, y) for x, y in zip(range(1,16), lr_list_lem)]\n",
    "lr_list_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like c = 0.1 is the best using Lemmatization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88744\n"
     ]
    }
   ],
   "source": [
    "final_ngram = LogisticRegression(C=0.1)\n",
    "final_ngram.fit(X, target)\n",
    "print(f'Final Accuracy: {accuracy_score(target, final_ngram.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1858332 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 208 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text1 = 'the best movie ever'\n",
    "sample_text2 = 'the worst movie ever'\n",
    "x1 = ngram_vect.transform([sample_text1])\n",
    "\n",
    "type(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_ngram.predict(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(string):\n",
    "    sent = final_ngram.predict(ngram_vect.transform([string]))\n",
    "    if sent == np.array([1]):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(sample_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
